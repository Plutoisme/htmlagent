import os
import time
import sys
import json
from typing import Dict, Any
from dotenv import load_dotenv
from openai import OpenAI

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from prompt import ENTIRE_PROMPT

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class SiliconFlowModel:
    def __init__(self):
        """åˆå§‹åŒ–ç¡…åŸºæµåŠ¨æ¨¡å‹å®¢æˆ·ç«¯"""
        self.api_key = os.getenv("SILICONFLOW_API_KEY")
        self.base_url = os.getenv("SILICONFLOW_BASE_URL", "https://api.siliconflow.cn/v1")
        
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½®SILICONFLOW_API_KEYç¯å¢ƒå˜é‡")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
    
    def generate_html_report(self, prompt: str) -> Dict[str, Any]:
        """
        è°ƒç”¨ç¡…åŸºæµåŠ¨æ¨¡å‹ç”ŸæˆHTMLæŠ¥å‘Šï¼ˆæµå¼è¾“å‡ºï¼‰
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            
        Returns:
            Dict[str, Any]: ç”Ÿæˆç»“æœ
        """
        try:
            print("ğŸ¤– å¼€å§‹è°ƒç”¨ç¡…åŸºæµåŠ¨æ¨¡å‹ï¼ˆæµå¼è¾“å‡ºï¼‰...")
            start_time = time.time()
            
            # æ ¹æ®å›¾ç‰‡ä¸­çš„å‚æ•°é…ç½®ï¼Œä½¿ç”¨æµå¼è¾“å‡º
            try:
                response = self.client.chat.completions.create(
                    model="Pro/deepseek-ai/DeepSeek-R1",
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    temperature=0.6,
                    max_tokens=52509,  # æ ¹æ®å›¾ç‰‡ä¸­çš„é…ç½®
                    top_p=0.95,
                    frequency_penalty=0.0,
                    thinking_budget=17996,  # æ ¹æ®å›¾ç‰‡ä¸­çš„é…ç½®
                    stream=True  # å¯ç”¨æµå¼è¾“å‡º
                )
            except Exception as e:
                # å¦‚æœæŸäº›å‚æ•°ä¸è¢«æ”¯æŒï¼Œå°è¯•ä¸ä½¿ç”¨è¿™äº›å‚æ•°
                error_msg = str(e).lower()
                if "thinking_budget" in error_msg or "top_k" in error_msg or "frequency_penalty" in error_msg:
                    print("âš ï¸ æŸäº›å‚æ•°ä¸è¢«æ”¯æŒï¼Œå°†ä½¿ç”¨åŸºç¡€å‚æ•°é…ç½®")
                    response = self.client.chat.completions.create(
                        model="Pro/deepseek-ai/DeepSeek-R1",
                        messages=[
                            {
                                "role": "user",
                                "content": prompt
                            }
                        ],
                        temperature=0.6,
                        max_tokens=52509,
                        top_p=0.95,
                        stream=True  # å¯ç”¨æµå¼è¾“å‡º
                    )
                else:
                    raise e
            
            # æ”¶é›†æµå¼è¾“å‡ºå†…å®¹
            content = ""
            print("ğŸ“ æ­£åœ¨æ¥æ”¶æµå¼è¾“å‡º...")
            
            for chunk in response:
                if not chunk.choices:
                    continue
                if chunk.choices[0].delta.content:
                    chunk_content = chunk.choices[0].delta.content
                    content += chunk_content
                    print(chunk_content, end="", flush=True)
                if chunk.choices[0].delta.reasoning_content:
                    reasoning_content = chunk.choices[0].delta.reasoning_content
                    content += reasoning_content
                    print(reasoning_content, end="", flush=True)
            
            print()  # æ¢è¡Œ
            
            # ç»“æŸè®¡æ—¶
            end_time = time.time()
            elapsed_time = end_time - start_time
            print(f"ğŸ¤– æ¨¡å‹è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            
            return {
                "success": True,
                "html_content": content,
                "model_call_time": elapsed_time
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {str(e)}"
            }

def main():
    """ä¸»å‡½æ•°ï¼šè°ƒç”¨æ¨¡å‹5æ¬¡å¹¶ä¿å­˜HTMLæŠ¥å‘Š"""
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        model = SiliconFlowModel()
        
        # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
        script_dir = os.path.dirname(os.path.abspath(__file__))
        
        # ç¡®ä¿report_generateç›®å½•å­˜åœ¨ï¼ˆç›¸å¯¹äºè„šæœ¬ç›®å½•ï¼‰
        os.makedirs(script_dir, exist_ok=True)
        
        print("ğŸš€ å¼€å§‹ç”ŸæˆHTMLæŠ¥å‘Š...")
        print(f"ğŸ“ ä½¿ç”¨æç¤ºè¯é•¿åº¦: {len(ENTIRE_PROMPT)} å­—ç¬¦")
        
        # è°ƒç”¨æ¨¡å‹5æ¬¡
        for i in range(1, 6):
            print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆç¬¬ {i} ä»½æŠ¥å‘Š...")
            
            # è°ƒç”¨æ¨¡å‹
            result = model.generate_html_report(ENTIRE_PROMPT)
            
            if result["success"]:
                # ç”Ÿæˆæ–‡ä»¶å
                timestamp = int(time.time())
                filename = f"report_{i}_{timestamp}.html"
                filepath = os.path.join(script_dir, filename)
                
                # ä¿å­˜HTMLå†…å®¹
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(result["html_content"])
                
                print(f"âœ… ç¬¬ {i} ä»½æŠ¥å‘Šå·²ä¿å­˜: {filename}")
                print(f"â±ï¸  ç”Ÿæˆè€—æ—¶: {result['model_call_time']:.2f}ç§’")
                print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {len(result['html_content'])} å­—ç¬¦")
                
            else:
                print(f"âŒ ç¬¬ {i} ä»½æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {result['error']}")
            
            # åœ¨æ¯æ¬¡è°ƒç”¨ä¹‹é—´ç¨ä½œåœé¡¿ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
            if i < 5:
                print("â³ ç­‰å¾…3ç§’åç»§ç»­...")
                time.sleep(3)
        
        print(f"\nğŸ‰ æ‰€æœ‰æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼å…±ç”Ÿæˆ {5} ä»½HTMLæŠ¥å‘Š")
        print(f"ğŸ“ æŠ¥å‘Šä¿å­˜åœ¨: {script_dir}")
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()
